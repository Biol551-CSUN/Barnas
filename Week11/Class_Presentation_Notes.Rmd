---
title: "Class Pacakge Presentations"
author: "Danielle Barnas"
date: "4/14/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

## Group2: Heatmaps with wHeatmaps

Load Packages
```{r}
library(wheatmap)
library(here)
library(tidyverse)
```

Data: mtcars
```{r}
mtcars_matrix <- as.matrix(mtcars)
head(mtcars_matrix)
```

Scale Data:
```{r}
mtcars_scale <- scale(mtcars_matrix)
```

Cluster Data:  
Lets us see variables that are closely related based on values and makes it more organized
```{r}
heatmap <- both.cluster(mtcars_scale)
heatmap$mat[,1:4] # creates our matrix dataframe
```

WHeatmap()
```{r}
BaseHeatmap <- WHeatmap(heatmap$mat,name = 'h1', # named h1 as heatmap 1 
                        yticklabels = TRUE, yticklabel.side = 'b', yticklabel.fontsize = 11,
                        xticklabels = TRUE, xticklabel.side = 'b', xticklabel.fontsize = 20,
                        cmp = CMPar(brewer.name = 'BuPu')) # uses brewer color palette without needing to load the brewer color package

BaseHeatmap
```

Exercise 1: move the xtick labels to the top of the map and change the color palette
```{r}
myHM <- WHeatmap(heatmap$mat,name = 'h2',
                        yticklabels = TRUE, yticklabel.side = 'a', yticklabel.fontsize = 11,
                        xticklabels = TRUE, xticklabel.side = 'a', xticklabel.fontsize = 20,
                        cmp = CMPar(brewer.name = 'Spectral')) # uses brewer color palette without needing to load the brewer color package

myHM
```

WDendrogram():  
You can choose how you want to place your dendrograms around the data. Shows similarities through clumping
```{r}
Dendrogram <- BaseHeatmap + #add axis labels
  WDendrogram(heatmap$row.clust, 
              LeftOf('h1'), #placement of dendrogram
              facing='right') 
Dendrogram
```

Exercise 2: If instead I wanted to place it on top of the heat map, facing down, what would the code look like?
```{r}
Dendrogram2 <- BaseHeatmap + #add axis labels
  WDendrogram(heatmap$column, 
              TopOf('h1'), #placement of dendrogram
              facing='bottom') 
Dendrogram2
```


WLegendV()
```{r}
Legend <- Dendrogram + 
  WLegendV('h1', BottomRightOf('h1', h.pad=.4), 'l1') #add legend
Legend
```
Example 3: Legend to the left of hte graph
```{r}
MyLegend <- Dendrogram + 
  WLegendV('h1', BottomLeftOf('h1', h.pad = -0.3), 'l1') #changing h.pad to a negative moves it off the plot.  Or remove it completely.
MyLegend
```

WRect(): Pointing out sections with a rectangle to show viewer
```{r}
Highlight <- Legend +
  WRect('h1',c(2,5),c(2,3),col='yellow') #highlight cells; col means color here
Highlight
```

## iNaturalist

rinat package

```{r}
library(rinat)
```

There's a shiny app to see your status as an iNaturalist user: app by Jonathan Layman

Data on iNaturalist contains geospatial data, which can be super useful for research, make sure to use Research Grade data

Downloading Data  
1. get_inat_obs()  
2. get_inat_obs_project()  
3. get_inat_obs_user()  

```{r}
get_inat_obs(query = "Parrotfishes", # any entry tha tmentions parrotfishes
             quality = "research") # only research grade observations
```

```{r}
get_inat_obs(taxon_id = 53353, # id number form iNaturalist (need to look up but gives more specific results)
             quality = "research") # only research grade observations
```
Place id
```{r}
get_inat_obs(place_id = 123751, year = 2020)
```

```{r}
library(tidyverse)
```

```{r}
Mule_deer <- get_inat_obs(query = "Mule Deer", # search for mule deer
                          bounds = c(38.44047, -125, 40.86652, -121.837), # geographic bounds
                          quality = "research",
                          year = 2019) # subset data by year
plot(Mule_deer$longitude, Mule_deer$latitude)
```


Project Data 

User Data
```{r}
get_inat_obs_user(username = "a_wandering_ecologist") # Richard's user id
```

Stats

Of a taxa: get_inat_taxon_stats()

Of a user: get_inat_user_stats()

All the stats from a certain place. Species logged in this location
```{r}
place_stats <- get_inat_taxon_stats(place = 123751)
place_stats
```

User stats from a Project
```{r}
project_user_stats <- get_inat_user_stats(project = "los-angeles-city-biodiversity-initiative")

project_user_stats[["total"]] # total number of users
```

Mapping

```{r}
library(here)
library(maps)
library(tidyverse)
```

inat_map function

```{r}
# lizard <- #some data frame from iNat
# 
# lizard_map <- inat_map(lizard)
# 
# lizard_map +
#   borders("stats") # etc....
```

Map using ggplot

```{r}
sceloporus <- get_inat_obs(taxon_name = "Sceloporus occidentalis",
                           quality = "research",
                           place_id = 962,
                           maxresults = 500)

squirrel <- get_inat_obs(taxon_name = "Sciurus niger",
                           quality = "research",
                           place_id = 962,
                           maxresults = 500)

bee <- get_inat_obs(taxon_name = "Apis mellifera",
                           quality = "research",
                           place_id = 962,
                           maxresults = 500)

animals <- rbind(bee, squirrel, sceloporus) # bind dataframes
```

Mapping the Data

```{r}
ggplot(data = animals, aes(x = longitude,
                           y = latitude,
                           colour = scientific_name)) +
  geom_polygon(data = map_data("usa"),
               aes(x = long, y = lat, group = group),
               fill = "grey95",
               color = "gray40",
               size = 0.1) +
  geom_point(size = 1, alpha = 0.5) +
  theme_bw()
```
Not helpful - data is clustered and can't see species differentiation on plot


```{r}
ggplot(data = animals, aes(x = longitude,
                           y = latitude,
                           colour = scientific_name)) +
  geom_polygon(data = map_data("usa"),
               aes(x = long, y = lat, group = group),
               fill = "grey95",
               color = "gray40",
               size = 0.1) +
  geom_point(size = 1, alpha = 0.5) +
  coord_fixed(xlim = range(animals$longitude, na.rm = T),
              ylim = range(animals$latitude, na.rm = T)) + # zoms into the map location only where we have data points
  theme_bw()
```


## See package

```{r}
library(see)
library(tidyverse)
library(here)
library(correlation)
library(ggraph)
library(tidytuesdayR)
library(gridExtra)
library(performance)

```


Load Data
```{r}
tuition_cost <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/tuition_cost.csv')
```


Density plot
```{r}
#view(tuition_cost) # check data structure, only used during early code composition
kirill_density <- tuition_cost # pass data to a new frame to preserve the original
x <- kirill_density %>% 
  pull(in_state_total) # create vector "x" with the data to be analyzed
  
density_kernel <- bayestestR::estimate_density(x) # perform the analysis, storing results in a new dataframe "density_kernel" (bayestestR is installed in with see package, but would need to load library separately w/o prefix)

hist(x, prob = TRUE, main = NULL, width = 10, height = 7, noRStudioGD = TRUE, xlab = "Total in-state spendings") # create a histogram for demonstration of the results of the function, remove default title, set size and use a parameter for correct rendering, set x axis label
lines(density_kernel$x, density_kernel$y, col = "black", lwd = 2) # set line color and width
title("estimate_density function over traditional histogram", lwd = 1)
legend("topright",
  legend = ("estimate_density output"),
  col = ("black"), lwd = 2, lty = c(1, 2)  # add legend, set width and line type to match rendered line
)
```


Check outliers

```{r}
kirill_outliers <- tuition_cost %>% # pass data to a new frame to preserve the original
  slice(1:30) # select the first 30 rows of data for visualization
model <- lm(room_and_board ~ in_state_tuition + out_of_state_tuition, data = kirill_outliers) # create a set of coordinates containing the linear model of the data based on relationship between room_and_board and combined effect of in_state_tuition and out_of_state_tuition
plot(performance::check_outliers(model, method = "zscore"), width = 10, height = 7) + # create plot and specify our function applied to the linear model as the input. Set method to Zscore
  theme(legend.position = "none") + # remove legend that would otherwise be a useless "Zscore"
  labs(title = "Outliers of the linear model and their Zscores",
       x = "Number of the institution in the list",
       y = "Deviation from the model") # set title and axes labels
```

Load new data from same tidytuesday
```{r}
# Salary potential
tuesdata <- tidytuesdayR::tt_load('2020-03-10')

salary <- tuesdata$salary_potential

salary_Corr <- correlation(salary) #creates matrix of correlation statistics between each variable; correlation function is part of easystats

# gives p values, r value, 95% confidence interval, t value, and degrees of freedom

salary_Corr
```

Create summary table of correlations between variables
```{r}
summary_corr <- summary(salary_Corr)
summary_corr
```


Can use the plot function in see to plot the correlations

```{r}
# pairwise heatmap

#Visualize correlations between all variables
#Plot function is from from see package helps efficiently visualize correlations between multiple variables 

plot_corr <- plot(summary_corr, 
                  show_values = TRUE, #r values 
                  show_p = TRUE, #show significance 
                  size_point = 3, #size of the points
                  size_text = 5, #size of the text
                  type = "tile") #Tile or circle
plot_corr
```

Labeled plots side by side  
Using see's Lucid theme
```{r}
tuition_clean <- tuition_cost %>% 
  filter(complete.cases(.))

p1 <- ggplot(tuition_clean, aes(x=room_and_board, y=in_state_tuition, color=type))+
  geom_point()+
  geom_smooth(method="lm")+
  theme_lucid()#Try one of See's added themes. More will be showcased later

p2 <- ggplot(tuition_clean, aes(x=in_state_tuition, y=out_of_state_tuition, color=type))+
  geom_point(size=1.2)+
 #geom_smooth(method="lm")+
  theme_lucid()+
  scale_color_pizza()

plots(p1, p2, tags = FALSE) #Package 'gridExtra' required for this function to work.
```

Custom tangs, rows, columns in multiple plots
```{r}
plots(p1, p2, tags = TRUE)

plots(p1, p2, n_rows = 2,
      tags = paste("Fig.", 1:3))

plots(p1, p2, n_columns = 2,
      tags = paste("Fig.", 1:3))
```

Bowling ball points with observation labels
```{r}
tuition_profit <- tuition_clean %>% #let's isolate a smaller set of data
  filter(type=="For Profit") %>% 
  filter(degree_length == "4 Year")

glimpse(tuition_profit)

ggplot(tuition_profit, aes(x = state, y = in_state_total))+
  geom_poolpoint(label=rownames(tuition_profit))+
  theme_lucid()+ #same theme as before from package
   theme(
    axis.text.x = element_text(size=8))
```

Half-violin plots
```{r}
tuition_cost %>% 
  filter(state %in% c("Colorado", "Alaska", "Kansas", "New York")) %>% # only keep a few states for aesthetics' sake
  ggplot(aes(x = state, y = in_state_tuition, fill = state)) + # set up a ggplot graph as you normally would
  labs(x = "State", # clean up labels
       y = "In-State Tuition") +
  geom_violinhalf() +
  theme_modern(legend.position = "none") + # use a See theme
  # All of the See scale options:
  # scale_fill_flat()
  # scale_fill_material()
  # scale_fill_metro()
  # scale_fill_pizza()
  # scale_fill_see()
  # scale_fill_social()
  scale_fill_bluebrown() # use a See scale
```

Half-violin/half-dot plot
```{r}
tuition_cost %>% 
  filter(state %in% c("Colorado", "Alaska", "Kansas", "New York")) %>% # only keep a few states for aesthetics' sake
  ggplot(aes(x = state, y = in_state_tuition, fill = state)) + # set up a ggplot graph as you normally would
  labs(x = "State", # clean up labels
       y = "In-State Tuition") +
  geom_violindot(dots_size = 20000) + # set up the half-violin half-dotplot; sizes can get weird with this geom
  theme_blackboard(legend.position = "none") + # use a See theme
  scale_fill_material() # use a See scale
```

Points without borders
```{r}
tuition_cost %>% 
  filter(state %in% c("Colorado", "Alaska", "Kansas", "New York")) %>% # only keep a few states for aesthetics' sake
  ggplot(aes(x = state, y = in_state_tuition, fill = state)) + 
  labs(x = "State", # clean up labels
       y = "In-State Tuition") +
  geom_jitter_borderless(size = 4) + # use geom_jitter_borderless for jittered "borderless" points
  theme_modern(legend.position = "none") + # use another See theme
  scale_fill_material() # use a See scale
```

Black borderless: gives a density plot vibe
```{r}
ggplot(tuition_cost, aes(x = in_state_tuition, y = room_and_board)) +
  labs(x = "In-State Tuition", # clean up labels
       y = "Room and Board") +
  geom_point2(size = 4, alpha = 0.3) + # use geom_point2 for plain, borderless points
  theme_modern() # use a See theme
```

Same same but with colors and a white border
```{r}
tuition_cost %>%
  filter(!type == "Other") %>%
  ggplot(aes(x = in_state_tuition, y = room_and_board, fill = type)) +
  labs(x = "In-State Tuition", # clean up labels
       y = "Room and Board",
       fill = "School Type") +
  geom_point_borderless(size = 4, alpha = 0.5) + # use geom_point2 for "borderless" points using multiple colors
  scale_fill_metro() + # use another See scale
  theme_modern() # use a See theme
```


## Janitor Package

Load libraries
```{r}
library(janitor)
library(tidyverse)
library(here)
library(readxl)
library(kableExtra)

```


If I clone the repo, I can use this data
```{r}
# coralgrowth<-read_csv(here("project", "Data", "CoralGrowth.csv"))
# corals_messy <- read_csv(here("project", "Data", "coraldata.csv"))

coralgrowth <- readr::read_csv('https://raw.githubusercontent.com/Biol551-CSUN/Janitor_Package/main/project/Data/CoralGrowth.csv')

corals_messy <- readr::read_csv('https://raw.githubusercontent.com/Biol551-CSUN/Janitor_Package/main/project/Data/CoralGrowth.csv')
```

There are many functions in this package that helps users clean up the data, so that it can be easier to use for data analysis and plot making. We will only be going over 5 of the most useful functons in the package.

-  clean_names()     
-  tabyl()           
-  remove_empty()
-  get_dupes()      
-  excel_numeric_to_date()


clean_names()

Ever have a time when the names of the columns in the data that you are using are all in different formats and it just looks like a mess?
Using the ***clean_names()*** function can help you with that, because it will change all of the column names so that they all have the same format. It will change all the names into lowercase letters with a _ as a separator.  


For example, in this data set we can see that all the column names have different formats. Some use a . as a separator, others use a _ 

```{r, message=TRUE}
corals_messy%>%
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>% #  Theme of the table
  kable_styling() %>% 
  scroll_box(width = "700px", height = "300px")# Table dimensions
```


To save you time and lines of code, you can just use the function     **clean_names()**. This will lead to the column names all to become lowercase and the separator is now a _

```{r}
corals<-clean_names(corals_messy) %>% ## function we are looking at ##
   write_csv(here("project", "output", "clean_names_corals.csv"))
corals %>%
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>% # the theme of the table
  kable_styling() %>%
  scroll_box(width = "700px", height = "300px") # table dimensions 
```


tably() 

To save you time and lines of code doing summary after summary use the **tabyl()** function. It will tell you the number of items of a value that you have, and their frequency. It essentially counts the number of times a character (you select)shows up and calculates the percentage that it makes up. The new values will show up as new columns. This function can be used in two ways... 

The first being a vector
```{r}
tabyl(corals, change_mg_cm2)%>% #we can put the object into a frequency table
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>% # theme of the table
  kable_styling() %>% 
  scroll_box(width = "300px", height = "300px")# table dimensions
```


To save us some time we can do the second method, which is using it as a function within a pipe.
```{r}
corals %>%
  tabyl(change_mg_cm2)%>%  ### The pipe version ###
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>% # theme of table
  kable_styling() %>%
  scroll_box(width = "300px", height = "300px")# table dimensions
```


remove_empty()

This does exactly as it says! It removes any fully empty columns or rows in your data set to help clean it up and made it easier to work with. Below, I show a small example, and then a realistic example with a larger data set. 

Steps to follow when using *remove_empty* 

```{r}
#first make a simple data frame 
a <- data.frame(v1 = c(7, 6, 4, 5),
                v2 = c(NA, NA, NA, NA),
                v3 = c("a", "b", "c", "d"), 
                v4 = c(6, 5, 8, 10))
a %>% #data frame name
  kbl()%>% #make a table in RMarkdown
  kable_classic()%>% #classic theme
  kable_styling(full_width = FALSE, position = "left")
a_clean<-a %>% #rename data frame
  remove_empty(c("rows", "cols")) #checks for empty columns and rows, removes them!
a_clean%>%  #data frame name 
  kbl()%>% #make a table in RMarkdown
  kable_classic()%>% #classic theme
  kable_styling(full_width = FALSE, position = "left")
```


Usefullness on a real data set 
```{r, message=FALSE}
coralgrowth %>% # data frame name
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>%
  kable_styling() %>%
  scroll_box(width = "700px", height = "300px")# classic theme
```

What we did was remove the column **X6** due to it being all NA's. 
```{r}
coralgrowth_clean<-coralgrowth %>%  #rename data set
  remove_empty(c("rows", "cols")) #remove any rows or columns with all NAs
coralgrowth_clean %>% # data frame name
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>%
  kable_styling() %>%
  scroll_box(width = "700px", height = "300px")# classic theme
```


get_dupes()

When we want to make ensure that there are no duplicates within our data the function to use is **get_dupes()**. The function counts the amount of duplicates there are, and shows us the row that the dupicate is in. 

```{r}
corals %>%
  get_dupes("change_mg_cm2")%>%  ## the function we are using ##
  arrange(dupe_count)%>%  # arranged it by dupe count to make it organized 
  kbl() %>% # make a table in RMarkdown
  kable_classic()%>% # table theme
  kable_styling() %>%
  scroll_box(width = "700px", height = "300px")# table dimensions 
```

This can be useful in many ways. We might be able to see that we recorded the same data twice. We can look for any data changes are the same and then see if they were treated the same. Potentially, showing us that two different treatments lead to the same results. 


excel_numeric_to_date()

In the event when we load data straight from excel, R tends to change the date to a series of numbers. This function decodes that for example:


**Data Before the Janitor Function**
| Date  | Session | Topic    |
|:------|:-------:|---------:|
| _left_ | _center_| _right_ |
|   41104| 1       | Anatomy |
|41105   |         | *Break* |
| 41106  | 2       | Tables  |
| 41107  |         | *Break* |

**How we use the Function: *excel_numeric_to_date()* **

In the event when we load data straight from excel, R tends to change the date to a series of numbers. This function decodes that for example:
```{r}
excel_numeric_to_date(41104)
excel_numeric_to_date(41105)
excel_numeric_to_date(41106)
excel_numeric_to_date(41107)
```
every set of numbers can be decoded to a certain day,


Data After the Janitor Function
| Date     | Session | Topic    |
|:---------|:-------:|---------:|
| _left_   | _center_| _right_ |
|2012-07-14| 1       | Anatomy |
|2012-07-15|         | *Break* |
|2012-07-16| 2       | Tables  |
|2012-07-17|         | *Break* |




